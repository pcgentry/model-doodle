{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all the classifiers, store them in estimators['classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import all_estimators\n",
    "\n",
    "estimator_types = ['classifier', 'regressor', 'cluster', 'transformer']\n",
    "estimator_list = all_estimators(type_filter='classifier')\n",
    "\n",
    "estimators = {}\n",
    "estimator_names = {}\n",
    "\n",
    "for estimator_type in estimator_types:\n",
    "    all_things = []\n",
    "    all_names = []\n",
    "    for name, thing in estimator_list:\n",
    "        try:\n",
    "#             print(f'{estimator_type}: {name}')\n",
    "            all_things.append(thing())\n",
    "            all_names.append(name)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    estimators[estimator_type] = all_things\n",
    "    estimator_names[estimator_type] = all_names\n",
    "\n",
    "all_estimators = zip(estimator_names, estimators)\n",
    "all_classifiers = zip(estimator_names['classifier'], estimators['classifier'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through all the classifiers\n",
    "... and see which one performs the best out-of-the-box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import timeit\n",
    "\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_metrics = [\"accuracy\", \"precision\", \"recall\", \"f1\"]\n",
    "# score_metrics = [\"accuracy\"]\n",
    "# score_metrics = [\"precision\"]\n",
    "# score_metrics = [\"recall\"]\n",
    "score_metrics = [\"f1\"]\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:99]\n",
    "y = iris.target[:99]\n",
    "\n",
    "kf = KFold(3)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "print(X.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- f1 ------------------------\n",
      "    ---- AdaBoostClassifier   ------\n",
      "--- AdaBoostClassifier ---\n",
      "f1 score: 1.0 (0.02401256500000004 seconds)\n",
      "--------------\n",
      "    ---- BaggingClassifier   ------\n",
      "--- BaggingClassifier ---\n",
      "f1 score: 1.0 (0.07960495700000036 seconds)\n",
      "--------------\n",
      "    ---- BernoulliNB   ------\n",
      "--- BernoulliNB ---\n",
      "f1 score: 0.5652173913043478 (0.01135765799999966 seconds)\n",
      "--------------\n",
      "    ---- CalibratedClassifierCV   ------\n",
      "--- CalibratedClassifierCV ---\n",
      "f1 score: 1.0 (0.06341564899999996 seconds)\n",
      "--------------\n",
      "    ---- CategoricalNB   ------\n",
      "--- CategoricalNB ---\n",
      "f1 score: 1.0 (0.014651811999999875 seconds)\n",
      "--------------\n",
      "    ---- ComplementNB   ------\n",
      "--- ComplementNB ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:683: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 674, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 199, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true,\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 236, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 53, in _cached_call\n",
      "    return getattr(estimator, method)(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\", line 120, in <lambda>\n",
      "    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/pipeline.py\", line 419, in predict\n",
      "    return self.steps[-1][-1].predict(Xt, **predict_params)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/naive_bayes.py\", line 75, in predict\n",
      "    jll = self._joint_log_likelihood(X)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sklearn/naive_bayes.py\", line 1303, in _joint_log_likelihood\n",
      "    jll += self.feature_log_prob_[i][:, indices].T\n",
      "IndexError: index 7 is out of bounds for axis 1 with size 7\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 1.0 (0.011051035000000375 seconds)\n",
      "--------------\n",
      "    ---- DecisionTreeClassifier   ------\n",
      "--- DecisionTreeClassifier ---\n",
      "f1 score: 1.0 (0.01584263599999991 seconds)\n",
      "--------------\n",
      "    ---- DummyClassifier   ------\n",
      "--- DummyClassifier ---\n",
      "f1 score: 0.5652173913043478 (0.0121676970000002 seconds)\n",
      "--------------\n",
      "    ---- ExtraTreeClassifier   ------\n",
      "--- ExtraTreeClassifier ---\n",
      "f1 score: 0.962962962962963 (0.012810232000000088 seconds)\n",
      "--------------\n",
      "    ---- ExtraTreesClassifier   ------\n",
      "--- ExtraTreesClassifier ---\n",
      "f1 score: 1.0 (0.5094670809999999 seconds)\n",
      "--------------\n",
      "    ---- GaussianNB   ------\n",
      "--- GaussianNB ---\n",
      "f1 score: 1.0 (0.01018718599999957 seconds)\n",
      "--------------\n",
      "    ---- GaussianProcessClassifier   ------\n",
      "--- GaussianProcessClassifier ---\n",
      "f1 score: 1.0 (0.024651720000000044 seconds)\n",
      "--------------\n",
      "    ---- GradientBoostingClassifier   ------\n",
      "--- GradientBoostingClassifier ---\n",
      "f1 score: 1.0 (0.17703587399999998 seconds)\n",
      "--------------\n",
      "    ---- HistGradientBoostingClassifier   ------\n",
      "--- HistGradientBoostingClassifier ---\n",
      "f1 score: 1.0 (0.35631742099999997 seconds)\n",
      "--------------\n",
      "    ---- KNeighborsClassifier   ------\n",
      "--- KNeighborsClassifier ---\n",
      "f1 score: 1.0 (0.01642913200000029 seconds)\n",
      "--------------\n",
      "    ---- LabelPropagation   ------\n",
      "--- LabelPropagation ---\n",
      "f1 score: 1.0 (0.011367114000000011 seconds)\n",
      "--------------\n",
      "    ---- LabelSpreading   ------\n",
      "--- LabelSpreading ---\n",
      "f1 score: 1.0 (0.011737801000000214 seconds)\n",
      "--------------\n",
      "    ---- LinearDiscriminantAnalysis   ------\n",
      "--- LinearDiscriminantAnalysis ---\n",
      "f1 score: 1.0 (0.011655737000000332 seconds)\n",
      "--------------\n",
      "    ---- LinearSVC   ------\n",
      "--- LinearSVC ---\n",
      "f1 score: 1.0 (0.010901017000000124 seconds)\n",
      "--------------\n",
      "    ---- LogisticRegression   ------\n",
      "--- LogisticRegression ---\n",
      "f1 score: 1.0 (0.04064665000000023 seconds)\n",
      "--------------\n",
      "    ---- LogisticRegressionCV   ------\n",
      "--- LogisticRegressionCV ---\n",
      "f1 score: 1.0 (0.7995759009999994 seconds)\n",
      "--------------\n",
      "    ---- MLPClassifier   ------\n",
      "--- MLPClassifier ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 1.0 (0.3448206549999995 seconds)\n",
      "--------------\n",
      "    ---- MultinomialNB   ------\n",
      "--- MultinomialNB ---\n",
      "f1 score: 1.0 (0.010572605999999318 seconds)\n",
      "--------------\n",
      "    ---- NearestCentroid   ------\n",
      "--- NearestCentroid ---\n",
      "f1 score: 1.0 (0.009170564999999797 seconds)\n",
      "--------------\n",
      "    ---- NuSVC   ------\n",
      "--- NuSVC ---\n",
      "f1 score: 1.0 (0.011419541999999616 seconds)\n",
      "--------------\n",
      "    ---- PassiveAggressiveClassifier   ------\n",
      "--- PassiveAggressiveClassifier ---\n",
      "f1 score: 1.0 (0.010786537999999624 seconds)\n",
      "--------------\n",
      "    ---- Perceptron   ------\n",
      "--- Perceptron ---\n",
      "f1 score: 1.0 (0.010582635999999646 seconds)\n",
      "--------------\n",
      "    ---- QuadraticDiscriminantAnalysis   ------\n",
      "--- QuadraticDiscriminantAnalysis ---\n",
      "f1 score: 1.0 (0.0077737829999993124 seconds)\n",
      "--------------\n",
      "    ---- RadiusNeighborsClassifier   ------\n",
      "--- RadiusNeighborsClassifier ---\n",
      "f1 score: 1.0 (0.009795710000000568 seconds)\n",
      "--------------\n",
      "    ---- RandomForestClassifier   ------\n",
      "--- RandomForestClassifier ---\n"
     ]
    }
   ],
   "source": [
    "score_accumulator = []\n",
    "grid_params = {\n",
    "    }\n",
    "\n",
    "for score_metric in score_metrics:\n",
    "    print(f\"----------------- {score_metric} ------------------------\")\n",
    "\n",
    "    for name, clf in all_classifiers:\n",
    "\n",
    "        try:\n",
    "            print(f\"    ---- {name}   ------\")\n",
    "            pipe = Pipeline([('classifier', clf)])\n",
    "    #         pipe = Pipeline([('scaler', StandardScaler()), ('classifier', clf)])\n",
    "\n",
    "            grid = GridSearchCV(pipe, grid_params, cv=kf, scoring = score_metric)\n",
    "            print(f\"--- {name} ---\")\n",
    "            timing = timeit.timeit(lambda: grid.fit(X_train, y_train), number=1)\n",
    "            score = grid.score(X_test, y_test)\n",
    "\n",
    "            print(f\"{score_metric} score: {score} ({timing} seconds)\")\n",
    "            print(f\"--------------\")\n",
    "\n",
    "            score_accumulator.append({\n",
    "            \"model\": name,\n",
    "            \"timing\": timing,\n",
    "            \"score\": score\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"nope.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(score_accumulator).sort_values(\"score\", ascending=False)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
